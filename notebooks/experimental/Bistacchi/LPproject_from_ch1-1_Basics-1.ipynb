{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My first test of geological modeling with GemPy - LP case study\n",
    "\n",
    "***\n",
    "Based on ch1-1_Basics.ipynb from Gempy tutorials\n",
    "***\n",
    "\n",
    "Here we test the most important steps of modeling with GemPy and we introduce essential objects and functions. Based on the LP cas study, We will illustrate how to:\n",
    "- import and create input data for modeling in GemPy\n",
    "- return and visualize input data\n",
    "- generate a 3D geological model in GemPy\n",
    "- visualize a model directly in GemPy\n",
    "\n",
    "***\n",
    "\n",
    "## The LP case study: simple folded stratigraphy and several faults\n",
    "\n",
    "Our model is defined within an exahedron, with an extent of 7000 x 6700 x 2500 m along x, y, z directions. It includes one fault (Fault_05) and five stratigraphic units (from top to bottom):\n",
    "\n",
    "- 01_Nant_Ffrancon_Fm\n",
    "- 02_Marchlyn_Fm\n",
    "- 03_Bronllwyd_Grit_Fm\n",
    "- 04_Llanberis_Slates_Fm\n",
    "- 05_Fachwen_Fm\n",
    "- basement (automatically added by GemPy)\n",
    "\n",
    "## Preparing the Python environment\n",
    "\n",
    "For modeling with GemPy, we first need to import it. We should also import any other packages we want to utilize in our Python environment.Typically, we will also require `NumPy` and `Matplotlib` when working with GemPy. At this point, we can further customize some settings as desired, e.g. the size of figures or, as we do here, the way that `Matplotlib` figures are displayed in our notebook (`%matplotlib inline`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# These two lines are necessary only if GemPy is not installed\n",
    "import sys, os\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "# Importing GemPy\n",
    "import gempy as gp\n",
    "\n",
    "# Embedding matplotlib figures in the notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing auxiliary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and creating a set of input data\n",
    "\n",
    "The data used for the construction of a model in GemPy is stored in Python objects. The main data classes are:\n",
    "\n",
    "    -  Surface_points\n",
    "    -  Orientations\n",
    "    -  Grid\n",
    "    -  Surfaces\n",
    "    -  Series\n",
    "    -  Additional data\n",
    "    -  Faults\n",
    "    \n",
    "We will see each of this class in further detail in the future.\n",
    "\n",
    "Most of data can also be generated from raw data that comes in the form of CSV-files (CSV = comma-separated values). Such files might be attained by exporting model data from a different or by simply creating it in a spreadsheet software.\n",
    "\n",
    "In this tutorial, all input data is created by importing such CSV-files. These **exemplary files** can be found in the `input_data` folder in the root folder of GemPy. \n",
    "The data include $x$-, $y$- and $z$-coordinate values for all surface points and orientation measurements. For the latter, poles, azimuth and polarity are additionally included. Surface points are furthermore assigned a formation. This might be a lithological unit such as \"Sandstone\" or a structural feature such as \"Main Fault\". It is decisive to remember that, in GemPy, interface position points mark the **bottom** of a layer. If such points are needed to resemble a top of a formation (e.g. when modeling an intrusion), this can be achieved by defining a respectively inverted orientation measurement.\n",
    "\n",
    "**NOTE:** This convention is the opposite as in other geomodeling packages such as SKUA-GOCAD or MOVE. The stratigraphy is not corrected for this issue here.\n",
    "\n",
    "As we generate our `Data` from CSV-files, we also have to define our model's real extent in $x$, $y$ and $z$, as well as declare a desired resolution for each axis. This resolution will in turn determine the number of voxels used during modeling. Here, we rely on a resolution of 70x67x25, amounting to 117,250 voxels. The model extent should be chosen in a way that it contains all relevant data in a representative space. As our model voxels are not cubes, but prisms, the resolution can take a different shape than the extent. We don't recommend going much higher than 100 cells in every direction (1,000,000 voxels), as higher resolutions will become increasingly difficult to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "geo_model = gp.create_model('LPproject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Importing the data from CSV-files and setting extent and resolution\n",
    "gp.init_data(geo_model,\n",
    "             [420100.,427100.,5880500.,5887200.,-1000.,1500.],\n",
    "             [70,67,25],\n",
    "             path_o = \"d:/Didattica/3D_Geomodelling/2019_corso/move2gempy_orientation_data/all_orientations.csv\",\n",
    "             path_i = \"d:/Didattica/3D_Geomodelling/2019_corso/move2gempy_point_data/all_surface_fault_points_light_faults.csv\",\n",
    "             default_values=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input data can then be listed using the command `get_data`. Note that the order of formations and respective allocation to series is still completely arbitrary. We will fix this in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "gp.get_data(geo_model, 'surface_points').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "gp.get_data(geo_model, 'orientations').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaring the sequential order of geological formations\n",
    "\n",
    "- TODO  @Fabian update this\n",
    "\n",
    "We want our geological units to appear in the correct order relative to age. Such order might for example be given by a depositional sequence of stratigraphy, unconformities due to erosion or other lithological genesis events such as igneous intrusions. A similar age-related order is to be declared for the faults in our model.\n",
    "In GemPy, the function *set_series* is used to assign formations to different sequential series via declaration in a Python dictionary.\n",
    "\n",
    "Defining the correct order of series is vital to the construction of the model! If you are using Python 3.6, the age-related order will already be defined by the order of key entries, i.e. the first entry is the youngest series, the last one the oldest. For older versions of Python, you will have to specify the correct order as a separate list attribute \"*order_series*\" (see cell below).\n",
    "\n",
    "You can assign several surfaces to one series. The order of the units within such as series is only relevant for the color code, thus we recommend to be consistent. You can define this order via another attribute \"*order_formations*\" or by using the specific command *set_order_formations*. (If the order of the pile differs from the final result the color of the interfaces and input data will be different. ?)\n",
    "\n",
    "Every fault is treated as an independent series and have to be at set at the **top of the pile**. The relative order between the distinct faults defines the tectonic relation between them (first entry is the youngest).\n",
    "\n",
    "In a model with simple sequential stratigraphy, all layer formations can be assigned to one single series without a problem. All unit boundaries and their order would then be given by interface points. However, to model more complex lithostratigraphical relations and interactions, the definition of separate series becomes important. For example, you would need to declare a \"newer\" series to model an unconformity or an intrusion that disturbs older stratigraphy.\n",
    "\n",
    "By default we create a simple sequence infered by the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our example model comprises five main layers (plus an underlying basement that is automatically generated by GemPy) and 13 faults. Assuming a simple stratigraphy where each younger unit was deposited onto the underlying older one, we can assign these layer formations to one series called \"Strat_Series\". For the fault, we declare a respective \"Fault_xx\" in the `set_series` dictionary. We could give any other names to these series, the formations however have to be referred to as named in the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "tags": [
     "nbval-ignore-output"
    ]
   },
   "outputs": [],
   "source": [
    "geo_model.surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "gp.map_series_to_surfaces(geo_model,\n",
    "                          {\"Fault_01\":'Fault_01',\n",
    "                           \"Fault_02\":'Fault_02',\n",
    "                           \"Fault_03\":'Fault_03',\n",
    "                           \"Fault_04\":'Fault_04',\n",
    "                           \"Fault_05\":'Fault_05',\n",
    "                           \"Fault_07\":'Fault_07',\n",
    "                           \"Fault_08\":'Fault_08',\n",
    "                           \"Fault_09\":'Fault_09',\n",
    "                           \"Fault_10\":'Fault_10',\n",
    "                           \"Fault_11\":'Fault_11',\n",
    "                           \"Fault_13\":'Fault_13',\n",
    "                           \"Fault_14\":'Fault_14',\n",
    "                           \"Fault_15\":'Fault_15',\n",
    "                           \"Strat_Series\":('00_above_Nant_Ffrancon_Fm','01_Nant_Ffrancon_Fm','02_Marchlyn_Fm','03_Bronllwyd_Grit_Fm','04_Llanberis_Slates_Fm','05_Fachwen_Fm','basement')},\n",
    "                          remove_unused_series=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "geo_model.series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set sratigraphic order. First index is the new order within the series **new_value**. Second index is the id that appears in the first column **idx**. Last parameter is the series name **series_name**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_model.modify_order_surfaces(1, 18, \"Strat_Series\")\n",
    "geo_model.modify_order_surfaces(2, 2, \"Strat_Series\")\n",
    "geo_model.modify_order_surfaces(3, 1, \"Strat_Series\")\n",
    "geo_model.modify_order_surfaces(4, 0, \"Strat_Series\")\n",
    "geo_model.modify_order_surfaces(5, 3, \"Strat_Series\")\n",
    "geo_model.modify_order_surfaces(6, 4, \"Strat_Series\")\n",
    "geo_model.modify_order_surfaces(7, 19, \"Strat_Series\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we set faults as faults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "geo_model.set_is_fault(['Fault_01'])\n",
    "geo_model.set_is_fault(['Fault_02'])\n",
    "geo_model.set_is_fault(['Fault_03'])\n",
    "geo_model.set_is_fault(['Fault_04'])\n",
    "geo_model.set_is_fault(['Fault_05'])\n",
    "geo_model.set_is_fault(['Fault_07'])\n",
    "geo_model.set_is_fault(['Fault_08'])\n",
    "geo_model.set_is_fault(['Fault_09'])\n",
    "geo_model.set_is_fault(['Fault_10'])\n",
    "geo_model.set_is_fault(['Fault_11'])\n",
    "geo_model.set_is_fault(['Fault_13'])\n",
    "geo_model.set_is_fault(['Fault_14'])\n",
    "geo_model.set_is_fault(['Fault_15'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we set all faults as finite faults, with their tipline within the modelling domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_model.set_is_finite_fault(['Fault_01'],toggle=True)\n",
    "geo_model.set_is_finite_fault(['Fault_02'],toggle=True)\n",
    "geo_model.set_is_finite_fault(['Fault_03'],toggle=True)\n",
    "geo_model.set_is_finite_fault(['Fault_04'],toggle=True)\n",
    "geo_model.set_is_finite_fault(['Fault_05'],toggle=True)\n",
    "geo_model.set_is_finite_fault(['Fault_07'],toggle=True)\n",
    "geo_model.set_is_finite_fault(['Fault_08'],toggle=True)\n",
    "geo_model.set_is_finite_fault(['Fault_09'],toggle=True)\n",
    "geo_model.set_is_finite_fault(['Fault_10'],toggle=True)\n",
    "geo_model.set_is_finite_fault(['Fault_11'],toggle=True)\n",
    "geo_model.set_is_finite_fault(['Fault_13'],toggle=True)\n",
    "geo_model.set_is_finite_fault(['Fault_14'],toggle=True)\n",
    "geo_model.set_is_finite_fault(['Fault_15'],toggle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we explore fault relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_model.faults.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "geo_model.faults.faults_relations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_model.faults.n_faults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_model.faults.count_faults(['Fault_01','Fault_02','Fault_03','Fault_04','Fault_05','Fault_07','Fault_08','Fault_09','Fault_10','Fault_11','Fault_13','Fault_14','Fault_15'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Returning information from our input data\n",
    "\n",
    "Our model input data, here named \"*geo_model*\", contains all the information that is essential for the construction of our model. You can access different types of information by using `gp.get_data` or simply by accessiong the atrribues.\n",
    "\n",
    "We can, for example, return the coordinates of our modeling grid via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "geo_model.grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned before, GemPy's core algorithm is based on interpolation of two types of data:\n",
    "- surface_points\n",
    "and\n",
    "- orientation measurements\n",
    "\n",
    "(if you want to know more on how this this interpolation algorithm works, checkout our chapter on the theory behind GemPy).\n",
    "\n",
    "We introduced the function *get_data* above. You can also specify which kind of data you want to call, by declaring the string attribute \"*dtype*\" to be either \"interfaces\" (surface points) or \"foliations\" (orientation measurements). \n",
    "\n",
    "#### Interfaces Dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "gp.get_data(geo_model, 'surface_points').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Orientations Dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gp.get_data(geo_model, 'orientations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that now all **surfaces** have been assigned to a **series** and are displayed in the correct order (from young to old).\n",
    "\n",
    "### Visualizing input data\n",
    "\n",
    "We can also visualize our input data. This might for example be useful to check if all points and measurements are defined the way we want them to. Using the function *plot_data*, we attain a 2D projection of our data points onto a plane of chosen *direction* (we can choose this attribute to be either $x$, $y$ or $z$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "gp.plot.plot_data(geo_model, direction='x');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "gp.plot.plot_data(geo_model, direction='y');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "gp.plot.plot_data(geo_model, direction='z');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using *plot_data_3D*, we can also visualize this data in 3D. Note that direct 3D visualization in GemPy requires [the Visualization Toolkit](https://www.vtk.org/) (VTK) to be installed.\n",
    "\n",
    "All 3D VTK plots in GemPy are interactive. This means that we can drag and drop any data poit and measurement. The perpendicular axis views in VTK are particularly useful to move points solely on a desired 2D plane. Any changes will then be stored permanently in the \"InputData\" dataframe. If we want to reset our data points, we will then need to reload our original input data.\n",
    "\n",
    "Executing the cell below will open a new window with a 3D interactive plot of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [],
   "source": [
    "#gp.plot.plot_3D(geo_model);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model generation\n",
    "\n",
    "Once we have made sure that we have defined all our primary information as desired in our object `DataManagement.InputData` (named `geo_data` in these tutorials), we can continue with the next step towards creating our geological model: preparing the input data for interpolation.\n",
    "\n",
    "This is done by generating an `InterpolatorData` object (named `interp_data` in these tutorials) from our `InputData` object via the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gp.set_interpolation_data(geo_model,\n",
    "                          compile_theano=True,\n",
    "                          theano_optimizer='fast_compile',\n",
    "                          verbose=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function rescales the extent and coordinates of the original data (and store it in the attribute `geo_data_res` which behaves as a usual `InputData` object) and adds mathematical parameters that are needed for conducting the interpolation. The computation of this step may take a while, as it also compiles a theano function which is required for the model computation. However, should this not be needed, we can skip it by declaring `compile_theano = False` in the function.\n",
    "\n",
    "Furthermore, this preparation process includes an assignment of numbers to each formation. Note that GemPy's always creates a default basement formation as the last formation number. Afterwards, numbers are allocated from youngest to oldest as defined by the sequence of series and formations. On the property `formations` on our interpolation data, we can find out which number has been assigned to which formation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters used for the interpolation can be returned using the function `get_kriging_parameters`. These are generated automatically from the orginal data, but can be changed if needed. However, users should be careful doing so, if they do not fully understand their significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "gp.get_data(geo_model, 'kriging')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have all we need to compute our full model via `compute_model`. By default, this will return two separate solutions in the form of arrays. The first gives information on the lithological formations, the second on the fault network in the model. These arrays consist of two subarrays as entries each:\n",
    "\n",
    "1. Lithology block model solution:\n",
    "    + Entry [0]: This array shows what kind of lithological formation is found in each voxel, as indicated by a respective formation_number.\n",
    "    + Entry [1]: Potential field array that represents the orientation of lithological units and layers in the block model.\n",
    "2. Fault network block model solution:\n",
    "    + Entry [0]: Array in which all fault-separated areas of the model are represented by a distinct number contained in each voxel.\n",
    "    + Entry [1}: Potential field array related to the fault network in the block model.\n",
    "    \n",
    "Below, we illustrate these different model solutions and how they can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "geo_model.additional_data.structure_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#sol = gp.compute_model(geo_model, compute_mesh=False, sort_surfaces=False)\n",
    "sol = gp.compute_model(geo_model, compute_mesh=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-check-output"
    ]
   },
   "outputs": [],
   "source": [
    "sol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct model visualization in GemPy\n",
    "\n",
    "Model solutions can be easily visualized in 2D sections in GemPy directly. Let's take a look at our lithology block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.compute_model(geo_model, compute_mesh=False, sort_surfaces=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "gp.plot.plot_section(geo_model, cell_number=25, direction='x', show_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "geo_model.surfaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `cell_number=25` and remembering that we defined our resolution to be 50 cells in each direction, we have chosen a section going through the middle of our block. We have moved 25 cells in `direction='y'`, the plot thus depicts a plane parallel to the $x$- and $y$-axes. Setting `plot_data=True`, we could plot original data together with the results. Changing the values for `cell_number`and `direction`, we can move through our 3D block model and explore it by looking at different 2D planes.\n",
    "\n",
    "We can do the same with out lithological scalar-field solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.plot.plot_scalar_field(geo_model, cell_number=25, N=15, series=1, \n",
    "                          direction='y', show_data=True, alpha=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This illustrates well the fold-related deformation of the stratigraphy, as well as the way the layers are influenced by the fault.\n",
    "\n",
    "The fault network modeling solutions can be visualized in the same way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.plot.plot_section(geo_model, cell_number=25, block=geo_model.solutions.block_matrix[0, 0], show_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marching cubes and vtk visualization\n",
    "\n",
    "In addition to 2D sections we can extract surfaces to visualize in 3D renderers. Surfaces can be visualized as 3D triangle complexes in VTK (see function plot_surfaces_3D below). To create these triangles, we need to extract respective vertices and simplices from the potential fields of lithologies and faults. This process is automatized in GemPy with the function get_surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ver , sim = gp.get_surfaces(geo_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [],
   "source": [
    "#gp.plot.plot_3D(geo_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the rescaled interpolation data, we can also run our 3D VTK visualization in an interactive mode which allows us to alter and update our model in real time. Similarly to the interactive 3D visualization of our input data, the changes are permamently saved (in the InterpolationInput dataframe object). Addtionally, the resulting changes in the geological models are re-computed in real time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute at a given location\n",
    "\n",
    "This is done by modifing the grid to a custom grid and recomputing. Notice that the results are given as *grid + surfaces_points_ref + surface_pontints_rest locations*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "x_i = np.array([[3,5,6]])\n",
    "sol = gp.compute_model_at(x_i, geo_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore if we just want the value at **x_i**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol[0][0, :x_i.shape[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GemPy uses  Python [pickle] for fast storing temporary objects (https://docs.python.org/3/library/pickle.html). However, module version consistency is required. For loading a pickle into GemPy, you have to make sure that you are using the same version of pickle and dependent modules (e.g.: `Pandas`, `NumPy`) as were used when the data was originally stored.\n",
    "\n",
    "For long term-safer storage we can export the `pandas.DataFrames` to csv by using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.save_model(geo_model, path=os.pardir+'/data/gempy_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "pandas.__version__"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "67px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
